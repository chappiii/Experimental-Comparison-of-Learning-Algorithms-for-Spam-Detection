{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190fed90-9e8a-485b-a833-f0db7c04b633",
   "metadata": {},
   "source": [
    "## Setting up the environment, loading & splitting of the data, and class distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901c4732-a1b2-42fc-ac50-65915d0eb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (%):\n",
      " 57\n",
      "0    60.595523\n",
      "1    39.404477\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset and split\n",
    "data = pd.read_csv(\"spambase.data\", header=None)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "n_splits = 10\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "class_distribution = y.value_counts(normalize=True) * 100\n",
    "print(\"Class Distribution (%):\\n\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2cc61-d26e-4e65-8495-e79f1affb60f",
   "metadata": {},
   "source": [
    "The class distribution is <mark>**60.6:39.4**</mark>, which indicates a mild imbalance, just meeting the threshold. Given the nature of the data—classified as Spam or Not Spam — <mark>**Recall**</mark> is a critical metric for evaluating model performance. This is because, in spam detection, minimizing false negatives (missed spam emails) is crucial to ensure a reliable system. Since the F1 score combines both **Precision** and **Recall**, it provides a balanced assessment of the model's performance. Therefore, we choose the <mark>**F1 score**</mark> as the primary metric for further comparison and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc7fb5-1350-4c35-a088-f666d7ffe326",
   "metadata": {},
   "source": [
    "## Helper function definations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456e297-711e-46e9-a525-d432da801711",
   "metadata": {},
   "source": [
    "Following three helper functions are used to \n",
    "- Perform Stratified k-fold  \n",
    "- F1 score comparison \n",
    "- Average rank statistics to find the Friedman statistic\\n \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfcc1ff-85d9-4e8f-a985-7f9bfa17d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to perform stratified k-fold and log results\n",
    "def stratified_k_fold_eval(model, model_name):\n",
    "    # Create a DataFrame to store fold results\n",
    "    results = []\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Fold\": fold_idx,\n",
    "            \"Training Time (s)\": train_time,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1 Score\": f1\n",
    "        })\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Compute Mean and Std\n",
    "    mean_row = {\n",
    "        \"Fold\": \"Mean\",\n",
    "        \"Training Time (s)\": results_df[\"Training Time (s)\"].mean(),\n",
    "        \"Accuracy\": results_df[\"Accuracy\"].mean(),\n",
    "        \"F1 Score\": results_df[\"F1 Score\"].mean()\n",
    "    }\n",
    "    std_row = {\n",
    "        \"Fold\": \"Std\",\n",
    "        \"Training Time (s)\": results_df[\"Training Time (s)\"].std(),\n",
    "        \"Accuracy\": results_df[\"Accuracy\"].std(),\n",
    "        \"F1 Score\": results_df[\"F1 Score\"].std()\n",
    "    }\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([mean_row, std_row])], ignore_index=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\nResults for {model_name}:\\n\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def f1_score_comparison(models):\n",
    "    # Initialize storage for F1 Score results\n",
    "    f1_results = {model_name: [] for model_name in models}\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        fold_f1_scores = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            # Split data\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions and metrics\n",
    "            y_pred = model.predict(X_test)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            # Store F1 Score for this fold\n",
    "            fold_f1_scores[model_name] = f1\n",
    "            f1_results[model_name].append(f1)\n",
    "        \n",
    "        # Rank F1 scores for the current fold\n",
    "        sorted_f1 = sorted(fold_f1_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        rankings = {name: rank + 1 for rank, (name, _) in enumerate(sorted_f1)}\n",
    "        \n",
    "        # Store F1 Score with rank in the results\n",
    "        for model_name in models:\n",
    "            f1_results[model_name][-1] = f\"{fold_f1_scores[model_name]:.4f} ({rankings[model_name]})\"\n",
    "    \n",
    "    # Generate a DataFrame for F1 Score comparison\n",
    "    table = {\"Fold\": [f\"Fold {i}\" for i in range(1, n_splits + 1)]}\n",
    "    for model_name in models:\n",
    "        table[model_name] = f1_results[model_name]\n",
    "    \n",
    "    # Calculate average rank for each model\n",
    "    avg_rank_row = [\"Avg Rank\"]\n",
    "    for model_name in models:\n",
    "        # Extract ranks from strings\n",
    "        ranks = [int(val.split('(')[-1].strip(')')) for val in f1_results[model_name]]\n",
    "        avg_rank = sum(ranks) / len(ranks)\n",
    "        avg_rank_row.append(f\"{avg_rank:.2f}\")\n",
    "    \n",
    "    # Add average rank row to the table\n",
    "    table[\"Fold\"].append(avg_rank_row[0])  # Add label to the Fold column\n",
    "    for idx, model_name in enumerate(models.keys(), start=1):\n",
    "        table[model_name].append(avg_rank_row[idx])\n",
    "    \n",
    "    # Convert table to DataFrame\n",
    "    results_df = pd.DataFrame(table)\n",
    "    \n",
    "    # Print the table\n",
    "    print(\"\\nF1 Score Comparison:\\n\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def calculate_rank_statistics(results_df):\n",
    "    # Extract the number of folds (n) and number of models (k)\n",
    "    n = len(results_df) - 1  # Exclude the last row (average ranks)\n",
    "    k = len(results_df.columns) - 1  # Exclude the \"Fold\" column\n",
    "\n",
    "    # Extract average ranks (last row excluding \"Fold\")\n",
    "    avg_ranks = results_df.iloc[-1, 1:].astype(float).values\n",
    "\n",
    "    # Calculate R_bar (average of the average ranks)\n",
    "    R_bar = np.mean(avg_ranks)\n",
    "\n",
    "    # Calculate N * SUM_j (Rj - R_bar)^2\n",
    "    N = n\n",
    "    term2 = N * np.sum((avg_ranks - R_bar) ** 2)\n",
    "\n",
    "    # Calculate (1 / (n - (k - 1))) * SUM_ij (Rij - Rj)^2\n",
    "    ranks_matrix = results_df.iloc[:n, 1:].map(lambda x: int(x.split('(')[-1].strip(')'))).values\n",
    "    term3 = (1 / (n * (k - 1))) * np.sum((ranks_matrix - R_bar) ** 2)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\n\")\n",
    "    print(f\"\\tR̅ = {R_bar:.4f}\")\n",
    "    print(f\"\\tN * Σj (Rj - R̅)^2 = {term2:.4f}\")\n",
    "    print(f\"\\t(1 / (n * (k - 1))) * Σij (Rij - Rj)^2 = {term3:.4f}\")\n",
    "\n",
    "    # Update DataFrame with R_bar on the top bar\n",
    "    results_df.loc[-1] = [\"R_bar\"] + [f\"{R_bar:.4f}\"] * k\n",
    "    results_df.index = results_df.index + 1\n",
    "    results_df.sort_index(inplace=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cfb6f4-b9dd-4cb2-9a59-cbe8d18f737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic Regression:\n",
      "\n",
      "Fold  Training Time (s)  Accuracy  F1 Score\n",
      "   1           1.476165  0.915401  0.892562\n",
      "   2           1.459002  0.923913  0.901961\n",
      "   3           1.156858  0.932609  0.913165\n",
      "   4           1.335482  0.936957  0.918768\n",
      "   5           1.211622  0.913043  0.890110\n",
      "   6           1.087201  0.936957  0.920110\n",
      "   7           1.698693  0.934783  0.915730\n",
      "   8           1.284989  0.932609  0.912676\n",
      "   9           1.353487  0.936957  0.915452\n",
      "  10           0.930187  0.915217  0.890141\n",
      "Mean           1.299368  0.927844  0.907067\n",
      " Std           0.218571  0.009952  0.012163\n",
      "\n",
      "Results for Random Forest:\n",
      "\n",
      "Fold  Training Time (s)  Accuracy  F1 Score\n",
      "   1           0.811631  0.952278  0.938889\n",
      "   2           0.752213  0.956522  0.944134\n",
      "   3           0.879899  0.960870  0.950000\n",
      "   4           0.858138  0.967391  0.957983\n",
      "   5           0.844638  0.945652  0.931129\n",
      "   6           0.838471  0.956522  0.944134\n",
      "   7           0.871480  0.958696  0.947368\n",
      "   8           0.820342  0.956522  0.943820\n",
      "   9           0.765990  0.941304  0.923513\n",
      "  10           0.847109  0.952174  0.937500\n",
      "Mean           0.828991  0.954793  0.941847\n",
      " Std           0.042360  0.007443  0.009720\n",
      "\n",
      "Results for XGBoost:\n",
      "\n",
      "Fold  Training Time (s)  Accuracy  F1 Score\n",
      "   1           0.367074  0.945770  0.931507\n",
      "   2           0.374614  0.958696  0.947075\n",
      "   3           0.314988  0.958696  0.948229\n",
      "   4           0.325059  0.960870  0.950000\n",
      "   5           0.340983  0.954348  0.942779\n",
      "   6           0.309312  0.956522  0.944444\n",
      "   7           0.345881  0.950000  0.936288\n",
      "   8           0.323987  0.958696  0.947945\n",
      "   9           0.349312  0.958696  0.947075\n",
      "  10           0.318582  0.945652  0.929178\n",
      "Mean           0.336979  0.954794  0.942452\n",
      " Std           0.022281  0.005666  0.007463\n",
      "\n",
      "F1 Score Comparison:\n",
      "\n",
      "    Fold Logistic Regression Random Forest    XGBoost\n",
      "  Fold 1          0.8926 (3)    0.9389 (1) 0.9315 (2)\n",
      "  Fold 2          0.9020 (3)    0.9441 (2) 0.9471 (1)\n",
      "  Fold 3          0.9132 (3)    0.9500 (1) 0.9482 (2)\n",
      "  Fold 4          0.9188 (3)    0.9580 (1) 0.9500 (2)\n",
      "  Fold 5          0.8901 (3)    0.9311 (2) 0.9428 (1)\n",
      "  Fold 6          0.9201 (3)    0.9441 (2) 0.9444 (1)\n",
      "  Fold 7          0.9157 (3)    0.9474 (1) 0.9363 (2)\n",
      "  Fold 8          0.9127 (3)    0.9438 (2) 0.9479 (1)\n",
      "  Fold 9          0.9155 (3)    0.9235 (2) 0.9471 (1)\n",
      " Fold 10          0.8901 (3)    0.9375 (1) 0.9292 (2)\n",
      "Avg Rank                3.00          1.50       1.50\n",
      "\n",
      "\n",
      "\tR̅ = 2.0000\n",
      "\tN * Σj (Rj - R̅)^2 = 15.0000\n",
      "\t(1 / (n * (k - 1))) * Σij (Rij - Rj)^2 = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation for all models\n",
    "all_results = {}\n",
    "for model_name, model in models.items():\n",
    "    all_results[model_name] = stratified_k_fold_eval(model, model_name)\n",
    "    \n",
    "# Run F1 Score comparison\n",
    "f1_comparison_table = f1_score_comparison(models)\n",
    "\n",
    "# Calculate the Friedman statistic\n",
    "updated_df = calculate_rank_statistics(f1_comparison_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37031bd5-1f80-4ae1-b1b1-3b58224b4ada",
   "metadata": {},
   "source": [
    "Since the Friedman statistic (15) is greater than the critical value (6.2), we reject the **Null Hypothesis**. This suggests that there is a significant difference between the performance of the tested models for the given data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993826b-b4ee-4330-a510-6c771f56576c",
   "metadata": {},
   "source": [
    "## Pairwise level analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41ce2a-1a07-451b-aaa7-ea82219cf565",
   "metadata": {},
   "source": [
    "Critical difference calculation\n",
    "\n",
    "$CD = q_\\alpha \\cdot \\sqrt{\\frac{k \\cdot (k+1)}{6 \\cdot N}}$  \n",
    "$= 2.343 \\cdot \\sqrt{\\frac{3 \\cdot 4}{6 \\cdot 10}}$  \n",
    "$= 2.343 \\cdot 0.45$  \n",
    "$= 1.05$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d164a-138b-4c3c-b2f0-4c5cfe2a33bf",
   "metadata": {},
   "source": [
    "### Final Analysis\n",
    "For \\( R_j = [1.5, 3.0, 1.5] \\) and \\( CD = 1.05 \\), the output will be:\n",
    "\n",
    "| Comparison                          | Rank Difference | Significant |\n",
    "|---------------------|---------------|-------------------------------|\n",
    "|Logistic Regression Vs Random Forest | 1.50            | True        |\n",
    "|Random Forest Vs XGBoost             | 0.00            | False       |\n",
    "|Logistic Regression Vs XGBoost       | 1.50            | True        |\n",
    "\n",
    "### ExplanLogistic Regression\n",
    "1. **Logistic Regression vs Random Forest:**  \n",
    "   \\( |1.5 - 3.0| = 1.5 \\)  \n",
    "   Since \\( 1.5 > 1.05 \\), this is **significant**.\n",
    "\n",
    "2. **Random Forest Vs XGBoost:**  \n",
    "   \\( |1.5 - 1.5| = 0.0 \\)  \n",
    "   Since \\( 0.0 \\leq 1.05 \\), this is **not significant**\n",
    "\n",
    "3. **Logistic Regressionnt** Vs **XGBoost**  \n",
    "   \\( |3.0 - 1.5| = 1.5 \\)  \n",
    "   Since \\( 1.5 > 1.05 \\), this is **significant**.\n",
    "\n",
    "This table summarizes the Nemenyi test results.\n",
    "i test results.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d4697-9e5d-4f76-9d4f-502cf8ad7eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
